{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#User: Sara Greenberg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.structure import SigmoidLayer, LinearLayer\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import data from csv and parse 'Posted' datetime to hour and minute\n",
    "raw_df = pd.read_csv('data/fbpost.csv')\n",
    "raw_df['Posted'] = pd.to_datetime(raw_df['Posted'])\n",
    "raw_df['Hour'] = raw_df['Posted'].dt.hour\n",
    "raw_df['Minute'] = raw_df['Posted'].dt.minute\n",
    "raw_parsed = raw_df.drop('Posted', axis=1)\n",
    "\n",
    "#Uncomment to view data as table\n",
    "#raw_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "0      television,series,entertainment,entertainment_...\n",
      "1      governmental_civilian,federal_government,busin...\n",
      "2      personal_care_products,water,microbeads,biotec...\n",
      "3      canada,canada_at_the_2011_parapan_american_gam...\n",
      "4      plant_reproduction,biology,beekeeping,health_m...\n",
      "5      mulcair,politics_of_canada,canada,quebec,thoma...\n",
      "6      josh_donaldson,sports,toronto_blue_jays,blue_j...\n",
      "7      governmental_civilian,federal_government,usd,d...\n",
      "8      baseball,a_j_burnett,cole_hamels,sports,mlb,tr...\n",
      "9      united_states,american,barack_obama,political,...\n",
      "10     social_issues,human_reproduction,fertility,abo...\n",
      "11     the_star,ontario,marineland,oceanaria,marine,m...\n",
      "12     military_personnel,civic_holiday,john_graves_s...\n",
      "13     patrick_patterson,sports,national_basketball_a...\n",
      "14     roddy_piper,entertainment,world_wrestling_ente...\n",
      "15     baseball,toronto_blue_jays,alex_anthopoulos,da...\n",
      "16     environment,canadian_coast_guard,disaster_acci...\n",
      "17     transport,lexus_rx,private_transport,donald_tr...\n",
      "18                                                      \n",
      "19     austin_hinchey,volleyball,binary_arithmetic,he...\n",
      "20     jonathan_bernier,sports,canadian,sports,toront...\n",
      "21     joel_dembe,tennis,sports,wheelchair_sports,whe...\n",
      "22     tituba,salem_witch_trials,religion,entertainme...\n",
      "23     enbridge_inc_,s_p_tsx_60_index,enbridge,econom...\n",
      "24                                                      \n",
      "25     special_investigations_unit,law_crime,law,lega...\n",
      "26     voice_registers,human_voice,phonetics,vocal_fr...\n",
      "27     caribbean,toronto,carnivals,ontario,provinces_...\n",
      "28     dylann_roof,sports,hate_crime,crimes,abuse,soc...\n",
      "29                                                      \n",
      "                             ...                        \n",
      "470    donald,binary_arithmetic,hexadecimal,relations...\n",
      "471    canadian,bombardier,business_finance,aviation,...\n",
      "472    judge,augusto_pinochet,military,chilean,rodrig...\n",
      "473    disaster_accident,environment,ecological_succe...\n",
      "474    pan_american_games,sports,pan_am,pan_am_games,...\n",
      "475    pan_american_games,pan_american_world_airways,...\n",
      "476    jose_bautista,sports,baseball,baseball,kansas_...\n",
      "477                                                     \n",
      "478    canadian,canada_post_corporation,quebec,politi...\n",
      "479                                                     \n",
      "480    toronto,toronto,summer_olympics,_2024_summer_o...\n",
      "481                                                     \n",
      "482                                                     \n",
      "483                                                     \n",
      "484                                                     \n",
      "485    american,sports,seattle_mariners,sports,cactus...\n",
      "486    greater_toronto_area,year_of_birth_missing,yea...\n",
      "487    damian_warner,decathlon,commonwealth_games,spo...\n",
      "488    patrick_brown,political,kathleen_wynne,politic...\n",
      "489                                                     \n",
      "490    jay_triano,sports,canada,basketball,sports,nat...\n",
      "491    bill_cosby,entertainment,black_sitcoms,televis...\n",
      "492    albert_schultz,soulpepper_theatre_company,toro...\n",
      "493    chinese,governmental_civilian,beijing,beijing,...\n",
      "494    path,path_toronto_,coalition_of_urban_and_metr...\n",
      "495                                                     \n",
      "496                                                     \n",
      "497                                                     \n",
      "498                                                     \n",
      "499                                                     \n",
      "Name: Keywords, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "from urllib2 import urlopen\n",
    "import json\n",
    "import re\n",
    "\n",
    "#This function goes to the facebook post link from the original data from Regina\n",
    "def get_keywords(facebookPostLink):\n",
    "    keywords = \"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(urlopen(facebookPostLink), 'html.parser')\n",
    "        for result in soup.find_all('code'):\n",
    "            if \"on.thestar\" in result.string:\n",
    "                m = re.search('on\\.thestar\\.com.*?&',result.string)\n",
    "                link = m.group(0).replace('%2F','/')\n",
    "                soup = BeautifulSoup(urlopen('http://' + link), 'html.parser')\n",
    "                url = soup.find_all('html')[0]['itemid'].replace('html','jsonp.html')\n",
    "                response = urlopen(url);\n",
    "                data = json.loads(response.read())\n",
    "                for keyword in data['keywords']:\n",
    "                    keyword = keyword.rsplit('/')\n",
    "                    keyword = keyword[len(keyword)-1]\n",
    "                    keywords = keywords + keyword + \",\"\n",
    "    except  (urllib2.HTTPError, KeyError):\n",
    "        print \"Error\"\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "#Get keywords from all links and save to csv\n",
    "raw_df['Keywords'] = pd.Series(np.zeros_like(raw_df['Permalink']))\n",
    "for i in range(0,len(raw_df['Permalink'])):\n",
    "    raw_df['Keywords'][i] = get_keywords(raw_df['Permalink'][i])\n",
    "print (raw_df['Keywords'])\n",
    "#raw_df.to_csv('fbpost_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "television\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = 'oc:socialtag/t/e/l/television'\n",
    "split = test.rsplit('/')\n",
    "print split[len(split)-1]\n",
    "#raw_df.to_csv('fbpost_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create input data - try using different features\n",
    "#raw_input = pd.concat([raw_parsed['Type'],raw_parsed['Hour'],raw_parsed['Minute']],axis=1, join='inner')\n",
    "#raw_input = pd.concat([raw_parsed['Type']],axis=1, join='inner')\n",
    "raw_input = pd.concat([raw_parsed['Hour'],raw_parsed['Minute']],axis=1, join='inner')\n",
    "dict = raw_input.T.to_dict().values();\n",
    "dv = DV( sparse = False );\n",
    "inputs = dv.fit_transform(dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create output data as a score\n",
    "outputs = (raw_parsed['Lifetime Post Total Reach'] + raw_parsed['Lifetime Post Consumptions'] - raw_parsed['Lifetime Negative feedback']).as_matrix()\n",
    "# from sklearn.preprocessing import normalize\n",
    "# outputs = normalize(outputs.astype(float))[0] Not needed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create and load dataset\n",
    "ds = SupervisedDataSet( 2, 1 )\n",
    "for i in range(0, len(inputs)):\n",
    "    ds.addSample(inputs[i], outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3ab5bbe2d3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                    )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackpropTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainUntilConvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxEpochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "#Build and train network\n",
    "net = buildNetwork(2,\n",
    "                   100, # number of hidden units\n",
    "                   1,\n",
    "                   bias = True,\n",
    "                   hiddenclass = SigmoidLayer,\n",
    "                   outclass = LinearLayer\n",
    "                   )\n",
    "\n",
    "trainer = BackpropTrainer(net, ds, verbose = False)\n",
    "trainer.trainUntilConvergence(maxEpochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [ 22.  30.]\n",
      "Net Output: [ 21873.1168872]\n",
      "Actual Output: 13165\n"
     ]
    }
   ],
   "source": [
    "#Preliminary testing -eventually, have separate training & testing data\n",
    "x = 1\n",
    "print 'Input: ' + str(inputs[x])\n",
    "print 'Net Output: ' + str(net.activate(inputs[x]))\n",
    "print 'Actual Output: ' + str(outputs[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00: [ 7899.58582398]\n",
      "0:15: [ 27672.27613963]\n",
      "1:00: [ 9293.29865506]\n",
      "1:15: [ 21873.1168872]\n",
      "2:00: [ 10946.54038687]\n",
      "2:15: [ 21873.1168872]\n",
      "3:00: [ 12321.92972432]\n",
      "3:15: [ 21873.1168872]\n",
      "4:00: [ 12321.92972496]\n",
      "4:15: [ 21873.1168872]\n",
      "5:00: [ 12321.92972502]\n",
      "5:15: [ 21873.1168872]\n",
      "6:00: [ 12321.92972503]\n",
      "6:15: [ 21873.1168872]\n",
      "7:00: [ 12321.92972503]\n",
      "7:15: [ 21873.1168872]\n",
      "8:00: [ 12321.92972503]\n",
      "8:15: [ 21873.1168872]\n",
      "9:00: [ 12321.92972503]\n",
      "9:15: [ 21873.1168872]\n",
      "10:00: [ 12321.92972503]\n",
      "10:15: [ 21873.1168872]\n",
      "11:00: [ 12321.92972503]\n",
      "11:15: [ 21873.1168872]\n",
      "12:00: [ 12321.92972503]\n",
      "12:15: [ 21873.1168872]\n",
      "13:00: [ 12321.92972503]\n",
      "13:15: [ 21873.1168872]\n",
      "14:00: [ 12321.92972503]\n",
      "14:15: [ 21873.1168872]\n",
      "15:00: [ 12321.92972503]\n",
      "15:15: [ 21873.1168872]\n",
      "16:00: [ 12321.92972503]\n",
      "16:15: [ 21873.1168872]\n",
      "17:00: [ 12321.92972503]\n",
      "17:15: [ 21873.1168872]\n",
      "18:00: [ 12321.92972503]\n",
      "18:15: [ 21873.1168872]\n",
      "19:00: [ 12321.92972503]\n",
      "19:15: [ 21873.1168872]\n",
      "20:00: [ 12321.92972503]\n",
      "20:15: [ 21873.1168872]\n",
      "21:00: [ 12321.92972503]\n",
      "21:15: [ 21873.1168872]\n",
      "22:00: [ 12321.92972503]\n",
      "22:15: [ 21873.1168872]\n",
      "23:00: [ 12321.92972503]\n",
      "23:15: [ 21873.1168872]\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "for i in range(0, 24):\n",
    "    print str(i) + \":00: \" + str(net.activate(array.array('f',[i,0.])))\n",
    "    print str(i) + \":15: \" + str(net.activate(array.array('f',[i,15.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
